{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ed9IsLP1W6Zr"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "4GWDKtoQXBA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Audio2Text\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr_MnzgAWtAy",
        "outputId": "0b29c5de-60f6-4f43-e226-1c8ebfd7ad48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Audio2Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from whisper import Whisper\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "whisper = Whisper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS3-J9mAZ-B4",
        "outputId": "696d834e-1e1b-4e83-b3b8-f0c1855c5a1d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('Model')\n",
        "processor.save_pretrained()"
      ],
      "metadata": {
        "id": "aQERXE6alWWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = whisper.predict('/content/Audio2Text/test_data/test_audio.ogg')"
      ],
      "metadata": {
        "id": "8J9A_T5zeOZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1LpOU6Fdyet",
        "outputId": "ae69d77b-d0bc-4ca0-9483-147a26107525"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "זאת בדיקת טקסט ראשונה למודל השפה של OpenAI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
        "import torch\n",
        "\n",
        "# Save model to local dir\n",
        "\n",
        "local_model_path = \"Model\"\n",
        "local_processor_path = \"AutoProcessor\"\n",
        "\n",
        "# Load model and processor\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained('openai/whisper-large-v3',torch_dtype =  torch.float16 if torch.cuda.is_available() else torch.float32, low_cpu_mem_usage = True, use_safetensors = True)\n",
        "processor = AutoProcessor.from_pretrained('openai/whisper-large-v3')\n",
        "\n",
        "# Save model and processor\n",
        "\n",
        "model.save_pretrained(local_model_path)\n",
        "processor.save_pretrained(local_processor_path)"
      ],
      "metadata": {
        "id": "7Allq3Vrlrf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trans(audio_path):\n",
        "  \"\"\"\n",
        "  an already built function that returns transcribed text\n",
        "\n",
        "  \"\"\"\n"
      ],
      "metadata": {
        "id": "HovDUuxXnNmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###gradio"
      ],
      "metadata": {
        "id": "YkTF8PROnvbT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "NDUgM6NQtTiE",
        "outputId": "0ae6eb2a-8688-4bc7-cf57-5237b2da793a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MIT License\\n\\nCopyright (c) 2022 OpenAI\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heKpVti6t6o_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Audio2Text\n",
        "!pip install -q -r requirements.txt\n",
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4SEsPqko6L2",
        "outputId": "70e3f5d2-249e-4082-9069-a05e0f4a95b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Audio2Text\n",
            "2024-08-13 07:52:12.709825: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-13 07:52:12.734292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-13 07:52:12.741565: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-13 07:52:12.758555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-13 07:52:14.672292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://def10cc6dca558c956.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/processing_utils.py:579: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://def10cc6dca558c956.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tests"
      ],
      "metadata": {
        "id": "0KQWMBdwgrL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O dev.tar.gz \"https://huggingface.co/datasets/imvladikon/hebrew_speech_kan/resolve/main/original_data/he/dev.tar.gz\"\n",
        "!tar -xzf dev.tar.gz"
      ],
      "metadata": {
        "id": "_SIE_03ImjIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "# Path to the tar.gz file\n",
        "tar_path = '/content/dev.tar.gz'"
      ],
      "metadata": {
        "id": "6i1NwH94mjsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from whisper import Whisper\n",
        "\n",
        "whisper = Whisper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cyOIkHkh-x",
        "outputId": "97e94f5d-23ba-48c7-b45d-d9133333278c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = '/content/dev/'\n",
        "files = os.listdir(path)\n",
        "wav_files = [file for file in sorted(files) if file.endswith('.wav')]\n",
        "txt_files = [file for file in sorted(files) if file.endswith('.txt')]\n",
        "size = 20\n",
        "wavs = [path + file for file in wav_files[:size]]\n",
        "txts = [path + file for file in txt_files[:size]]\n",
        "df = pd.DataFrame(dict(wav=wavs,txt=txts))\n",
        "df.head()\n",
        "\n",
        "df['ground_truth'] = df.txt.apply(lambda x: open(x, 'r').read())\n",
        "df['prediction'] = df.wav.apply(lambda x: whisper.predict(x))\n",
        "\n",
        "df.drop(columns=['wav','txt'], axis=1, inplace=True)\n",
        "\n",
        "df[['prediction','ground_truth']].head(60)"
      ],
      "metadata": {
        "id": "8j-uMWK0lsSj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}